{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YouBike租借次數預測.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/kevin900804/Deep_Learning_YouBike_Predict/main/YouBike_Data.csv\n",
        "!wget https://raw.githubusercontent.com/kevin900804/Deep_Learning_YouBike_Predict/main/YouBike_Data_Test.csv\n",
        "!wget https://raw.githubusercontent.com/kevin900804/Deep_Learning_YouBike_Predict/main/YouBike_Data_All.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngr_uEvsljfz",
        "outputId": "85392494-85d1-4b7e-faeb-be3940fc7133"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-19 09:01:36--  https://raw.githubusercontent.com/kevin900804/Deep_Learning_YouBike_Predict/main/YouBike_Data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2519 (2.5K) [text/plain]\n",
            "Saving to: ‘YouBike_Data.csv’\n",
            "\n",
            "\rYouBike_Data.csv      0%[                    ]       0  --.-KB/s               \rYouBike_Data.csv    100%[===================>]   2.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-19 09:01:36 (55.6 MB/s) - ‘YouBike_Data.csv’ saved [2519/2519]\n",
            "\n",
            "--2022-07-19 09:01:36--  https://raw.githubusercontent.com/kevin900804/Deep_Learning_YouBike_Predict/main/YouBike_Data_Test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2557 (2.5K) [text/plain]\n",
            "Saving to: ‘YouBike_Data_Test.csv’\n",
            "\n",
            "YouBike_Data_Test.c 100%[===================>]   2.50K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-19 09:01:36 (55.6 MB/s) - ‘YouBike_Data_Test.csv’ saved [2557/2557]\n",
            "\n",
            "--2022-07-19 09:01:36--  https://raw.githubusercontent.com/kevin900804/Deep_Learning_YouBike_Predict/main/YouBike_Data_All.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2832 (2.8K) [text/plain]\n",
            "Saving to: ‘YouBike_Data_All.csv’\n",
            "\n",
            "YouBike_Data_All.cs 100%[===================>]   2.77K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-19 09:01:36 (59.1 MB/s) - ‘YouBike_Data_All.csv’ saved [2832/2832]\n",
            "\n",
            "wget: option '--output' is ambiguous; possibilities: '--output-document' '--output-file'\n",
            "Usage: wget [OPTION]... [URL]...\n",
            "\n",
            "Try `wget --help' for more options.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YpDhvTOfG_Y1"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def same_seed(seed): \n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def train_valid_split(data_set, valid_ratio, seed):\n",
        "    valid_set_size = int(valid_ratio * len(data_set))\n",
        "    train_set_size = len(data_set) - valid_set_size\n",
        "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
        "    return np.array(train_set), np.array(valid_set)\n",
        "\n",
        "def predict(test_loader, model, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    for x in tqdm(test_loader):\n",
        "        x = x.to(device)                       \n",
        "        with torch.no_grad():              \n",
        "            pred = model(x)                     \n",
        "            preds.append(pred.detach().cpu())\n",
        "    preds = torch.cat(preds, dim=0).numpy()\n",
        "    return preds"
      ],
      "metadata": {
        "id": "FLEjj0F-tStL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YouBikeDataset(Dataset):\n",
        "    def __init__(self, x, y=None):\n",
        "        if y is None: \n",
        "            self.y = y\n",
        "        else:\n",
        "            self.y = torch.FloatTensor(y)\n",
        "        self.x = torch.FloatTensor(x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is None:\n",
        "            return self.x[idx]\n",
        "        else:\n",
        "            return self.x[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ],
      "metadata": {
        "id": "Y6bNlZXg5UCa"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class My_Model(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(My_Model, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        x = x.squeeze(1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "CkVuieZzNKrB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "data = pd.read_csv('./YouBike_Data.csv')\n",
        "x = data[data.columns[1:11]]\n",
        "y = data[data.columns[11]]\n",
        "from sklearn import preprocessing\n",
        "x = (x - x.min()) / (x.max() - x.min())\n",
        "\n",
        "bestfeatures = SelectKBest(score_func=f_regression,k='all')\n",
        "fit = bestfeatures.fit(x,y)\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(x.columns)\n",
        "\n",
        "bestfeatures = SelectKBest(score_func=f_regression)\n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Variables','Score']  \n",
        "print(featureScores.nlargest(10,'Score'))"
      ],
      "metadata": {
        "id": "9xxvdO1REHe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9be3dc-1f5e-4011-f6ff-c5c77ec41f87"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   Variables     Score\n",
            "0                               rainfall(mm)  2.534780\n",
            "6                           num_of_rainy_day  1.311336\n",
            "3                               num_of_bikes  0.476641\n",
            "5                  insolation_duration(hour)  0.263690\n",
            "9                             last_12_months  0.221171\n",
            "4                 total_bike_lane_length(km)  0.175166\n",
            "1       monthly_average_temperature(Celsius)  0.144311\n",
            "2                       num_of_bike_stations  0.112669\n",
            "8  num_of_scooters_owned_per_thousand_people  0.070508\n",
            "7      num_of_cars_owned_per_thousand_people  0.006026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def select_feat(train_data, valid_data, test_data, select_all=True):\n",
        "    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n",
        "    raw_x_train, raw_x_valid, raw_x_test = train_data[:,1:-1], valid_data[:,1:-1], test_data[:,1:]\n",
        "    if select_all:\n",
        "        feat_idx = list(range(raw_x_train.shape[1]))\n",
        "    else:\n",
        "        feat_idx = [0,6,3,5]\n",
        "    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid"
      ],
      "metadata": {
        "id": "vO2RNO4zA5Ws"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "k4Rq8_TztAhq"
      },
      "outputs": [],
      "source": [
        "def trainer(train_loader, valid_loader, model, config, device):\n",
        "    criterion = nn.MSELoss(reduction='mean') \n",
        "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.01)\n",
        "\n",
        "    writer = SummaryWriter()\n",
        "\n",
        "    if not os.path.isdir('./models'):\n",
        "        os.mkdir('./models')\n",
        "\n",
        "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        loss_record = []\n",
        "\n",
        "        train_pbar = tqdm(train_loader, position=0, leave=True)\n",
        "\n",
        "        for x, y in train_pbar:\n",
        "            optimizer.zero_grad()               \n",
        "            x, y = x.to(device), y.to(device)    \n",
        "            pred = model(x)             \n",
        "            loss = criterion(pred, y)\n",
        "            loss.backward()                     \n",
        "            optimizer.step()                    \n",
        "            step += 1\n",
        "            loss_record.append(loss.detach().item()) \n",
        "            \n",
        "            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
        "            train_pbar.set_postfix({'loss': loss.detach().item()})\n",
        "\n",
        "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
        "        writer.add_scalar('Loss/train', mean_train_loss, step)\n",
        "\n",
        "        model.eval()\n",
        "        loss_record = []\n",
        "        for x, y in valid_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                loss = criterion(pred, y)\n",
        "\n",
        "            loss_record.append(loss.item())\n",
        "            \n",
        "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
        "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
        "        writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
        "        \n",
        "        if mean_valid_loss < best_loss:\n",
        "            best_loss = mean_valid_loss\n",
        "            torch.save(model.state_dict(), config['save_path'])\n",
        "            print('Saving model with loss {:.3f}...'.format(best_loss))\n",
        "            early_stop_count = 0\n",
        "        else: \n",
        "            early_stop_count += 1 \n",
        "\n",
        "        if early_stop_count >= config['early_stop']: \n",
        "            print('\\nModel is not improving, so we halt the training session.')\n",
        "            return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "8Jy4Dw6tjAtQ"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "config = {\n",
        "    'seed': 4096,\n",
        "    'select_all': False,\n",
        "    'valid_ratio': 0.2,\n",
        "    'n_epochs': 10000,            \n",
        "    'batch_size': 50, \n",
        "    'learning_rate': 1e-5,              \n",
        "    'early_stop': 1000,     \n",
        "    'save_path': './models/model.ckpt'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2jc7ZfDot2t9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638c1619-acf4-42cc-ef7b-ac4ac0025502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data size: (29, 12) \n",
            "valid_data size: (7, 12) \n",
            "test_data size: (41, 11)\n",
            "number of features: 4\n"
          ]
        }
      ],
      "source": [
        "same_seed(config['seed'])\n",
        "\n",
        "train_data, test_data = pd.read_csv('./YouBike_Data.csv').values, pd.read_csv('./YouBike_Data_Test.csv').values\n",
        "train_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n",
        "\n",
        "print(f\"\"\"train_data size: {train_data.shape} \n",
        "valid_data size: {valid_data.shape} \n",
        "test_data size: {test_data.shape}\"\"\")\n",
        "\n",
        "x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config['select_all'])\n",
        "\n",
        "print(f'number of features: {x_train.shape[1]}')\n",
        "\n",
        "train_dataset, valid_dataset, test_dataset = YouBikeDataset(x_train, y_train), \\\n",
        "                                             YouBikeDataset(x_valid, y_valid), \\\n",
        "                                             YouBikeDataset(x_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = My_Model(input_dim=x_train.shape[1]).to(device)\n",
        "trainer(train_loader, valid_loader, model, config, device)"
      ],
      "metadata": {
        "id": "SWY6S67iYAW6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f65a1be4-1871-419c-9239-9285350b188d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/10000]: 100%|██████████| 1/1 [00:05<00:00,  5.79s/it, loss=1.08e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10000]: Train loss: 1082.0540, Valid loss: 339.9699\n",
            "Saving model with loss 339.970...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [2/10000]: 100%|██████████| 1/1 [00:00<00:00, 93.13it/s, loss=484]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10000]: Train loss: 483.9357, Valid loss: 78.7697\n",
            "Saving model with loss 78.770...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [3/10000]: 100%|██████████| 1/1 [00:00<00:00, 105.54it/s, loss=140]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10000]: Train loss: 140.1974, Valid loss: 19.2243\n",
            "Saving model with loss 19.224...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [4/10000]: 100%|██████████| 1/1 [00:00<00:00, 125.00it/s, loss=21.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10000]: Train loss: 21.2235, Valid loss: 16.3251\n",
            "Saving model with loss 16.325...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [5/10000]: 100%|██████████| 1/1 [00:00<00:00, 118.17it/s, loss=16.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10000]: Train loss: 16.3500, Valid loss: 14.2379\n",
            "Saving model with loss 14.238...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [6/10000]: 100%|██████████| 1/1 [00:00<00:00, 111.53it/s, loss=14.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10000]: Train loss: 14.2241, Valid loss: 12.6866\n",
            "Saving model with loss 12.687...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [7/10000]: 100%|██████████| 1/1 [00:00<00:00, 122.43it/s, loss=12.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10000]: Train loss: 12.6301, Valid loss: 11.5070\n",
            "Saving model with loss 11.507...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [8/10000]: 100%|██████████| 1/1 [00:00<00:00, 26.57it/s, loss=11.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10000]: Train loss: 11.4033, Valid loss: 10.5853\n",
            "Saving model with loss 10.585...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [9/10000]: 100%|██████████| 1/1 [00:00<00:00, 91.77it/s, loss=10.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10000]: Train loss: 10.4441, Valid loss: 9.8471\n",
            "Saving model with loss 9.847...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [10/10000]: 100%|██████████| 1/1 [00:00<00:00, 120.01it/s, loss=9.69]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10000]: Train loss: 9.6855, Valid loss: 9.2517\n",
            "Saving model with loss 9.252...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [11/10000]: 100%|██████████| 1/1 [00:00<00:00, 106.63it/s, loss=9.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/10000]: Train loss: 9.0747, Valid loss: 8.7715\n",
            "Saving model with loss 8.772...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [12/10000]: 100%|██████████| 1/1 [00:00<00:00, 101.85it/s, loss=8.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/10000]: Train loss: 8.5784, Valid loss: 8.3706\n",
            "Saving model with loss 8.371...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [13/10000]: 100%|██████████| 1/1 [00:00<00:00, 112.86it/s, loss=8.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/10000]: Train loss: 8.1694, Valid loss: 8.0330\n",
            "Saving model with loss 8.033...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [14/10000]: 100%|██████████| 1/1 [00:00<00:00, 104.97it/s, loss=7.83]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/10000]: Train loss: 7.8266, Valid loss: 7.7465\n",
            "Saving model with loss 7.747...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [15/10000]: 100%|██████████| 1/1 [00:00<00:00, 105.21it/s, loss=7.53]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/10000]: Train loss: 7.5348, Valid loss: 7.5017\n",
            "Saving model with loss 7.502...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [16/10000]: 100%|██████████| 1/1 [00:00<00:00, 89.31it/s, loss=7.28]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/10000]: Train loss: 7.2844, Valid loss: 7.2910\n",
            "Saving model with loss 7.291...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [17/10000]: 100%|██████████| 1/1 [00:00<00:00, 104.11it/s, loss=7.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/10000]: Train loss: 7.0679, Valid loss: 7.1083\n",
            "Saving model with loss 7.108...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [18/10000]: 100%|██████████| 1/1 [00:00<00:00, 102.49it/s, loss=6.88]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/10000]: Train loss: 6.8792, Valid loss: 6.9488\n",
            "Saving model with loss 6.949...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [19/10000]: 100%|██████████| 1/1 [00:00<00:00, 106.81it/s, loss=6.71]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/10000]: Train loss: 6.7137, Valid loss: 6.8082\n",
            "Saving model with loss 6.808...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [20/10000]: 100%|██████████| 1/1 [00:00<00:00, 115.07it/s, loss=6.57]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/10000]: Train loss: 6.5672, Valid loss: 6.6835\n",
            "Saving model with loss 6.684...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [21/10000]: 100%|██████████| 1/1 [00:00<00:00, 37.82it/s, loss=6.44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/10000]: Train loss: 6.4366, Valid loss: 6.5718\n",
            "Saving model with loss 6.572...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [22/10000]: 100%|██████████| 1/1 [00:00<00:00, 102.08it/s, loss=6.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/10000]: Train loss: 6.3192, Valid loss: 6.4708\n",
            "Saving model with loss 6.471...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [23/10000]: 100%|██████████| 1/1 [00:00<00:00, 84.12it/s, loss=6.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/10000]: Train loss: 6.2126, Valid loss: 6.3787\n",
            "Saving model with loss 6.379...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [24/10000]: 100%|██████████| 1/1 [00:00<00:00, 80.58it/s, loss=6.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/10000]: Train loss: 6.1151, Valid loss: 6.2937\n",
            "Saving model with loss 6.294...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [25/10000]: 100%|██████████| 1/1 [00:00<00:00, 26.94it/s, loss=6.02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/10000]: Train loss: 6.0250, Valid loss: 6.2147\n",
            "Saving model with loss 6.215...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [26/10000]: 100%|██████████| 1/1 [00:00<00:00, 119.37it/s, loss=5.94]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/10000]: Train loss: 5.9409, Valid loss: 6.1403\n",
            "Saving model with loss 6.140...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [27/10000]: 100%|██████████| 1/1 [00:00<00:00, 113.65it/s, loss=5.86]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/10000]: Train loss: 5.8618, Valid loss: 6.0696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model with loss 6.070...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [28/10000]:   0%|          | 0/1 [00:00<?, ?it/s, loss=5.79]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-036b9f2dcca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMy_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-7c8175d96e50>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(train_loader, valid_loader, model, config, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtrain_pbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch [{epoch+1}/{n_epochs}]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mtrain_pbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mmean_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mset_postfix\u001b[0;34m(self, ordered_dict, refresh, **kwargs)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                                  for key in postfix.keys())\n\u001b[1;32m   1444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_postfix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mprint_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mlen_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisp_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m             \u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mfp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mfp_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mlast_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=./runs/"
      ],
      "metadata": {
        "id": "nFk5m3Xxq9aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5eVdpbvAlAe"
      },
      "outputs": [],
      "source": [
        "def save_pred(preds, file):\n",
        "    with open(file, 'w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['year_month', 'num_of_bicycle_rentals(million)'])\n",
        "        for i, p in enumerate(preds):\n",
        "            writer.writerow([i, p])\n",
        "\n",
        "model = My_Model(input_dim=x_train.shape[1]).to(device)\n",
        "model.load_state_dict(torch.load(config['save_path']))\n",
        "preds = predict(test_loader, model, device) \n",
        "save_pred(preds, 'pred.csv')         "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "This notebook refers to code written by Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)"
      ],
      "metadata": {
        "id": "IJ_k5rY0GvSV"
      }
    }
  ]
}